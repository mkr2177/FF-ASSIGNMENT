# ğŸ“ˆ Stock Price Prediction Using Machine Learning

## ğŸ“„ Assignment Context

This project is developed as part of the **Futures First Internship Assignment**.  
All steps, assumptions, and methodologies strictly follow the problem statement and guidelines provided in the assignment PDF.

---

## ğŸ“Œ Problem Statement

You are provided with two datasets:

- **Data Dataset** â€“ Independent variable  
- **StockPrice Dataset** â€“ Dependent variable (stock prices)

The task is to build a **Python-based machine learning model** to predict stock prices using values from the Data dataset.

---

## ğŸ§  Key Assumptions (As Given in PDF)

1. **Primary Influence**  
   Stock price movement is primarily influenced by the **change in data from the previous day**.

2. **Other Factors Ignored**  
   Although many real-world variables influence stock prices, **all other factors are ignored** for the purpose of this assignment.

These assumptions were strictly respected throughout the project.

---

## ğŸ¯ Project Objectives

- Load and preprocess the given datasets
- Engineer features capturing **day-over-day changes**
- Normalize features where required
- Train machine learning models to predict stock prices
- Evaluate model performance using suitable metrics
- Interpret results using visualizations
- Compare linear and non-linear models
- Provide reusable prediction functions

---

## ğŸ§  Overall Workflow

The project follows a complete **end-to-end machine learning pipeline**:

1. Data loading  
2. Date handling and merging  
3. Missing value analysis  
4. Feature engineering  
5. Feature scaling  
6. Exploratory data analysis (EDA)  
7. Train-test split  
8. Model training  
9. Model evaluation  
10. Visualization  
11. Prediction on new data  
12. Model comparison  

---

## ğŸ§¹ Data Preprocessing

### 1ï¸âƒ£ Data Loading
- Loaded datasets using **Pandas**
- Files used:
  - `Data1.csv`
  - `StockPrice.csv`

### 2ï¸âƒ£ Date Handling
- Converted `Date` columns to `datetime` format
- Ensured consistent date alignment

### 3ï¸âƒ£ Data Merging
- Merged datasets using an **inner join on Date**
- Ensured only common dates were retained
- Sorted merged dataset chronologically

### 4ï¸âƒ£ Missing Value Check
- Checked missing values using `isnull().sum()`
- No missing values were found except those introduced during feature engineering

---

## ğŸ— Feature Engineering

### Core Feature (Based on Assignment Assumption)


- Captures **day-over-day change**
- Directly reflects the assignmentâ€™s assumption
- First value filled with `0` to handle missing value from differencing

### Final Features Used
- `Data`
- `Data_Change`

---

## âš– Feature Scaling

- Applied **StandardScaler**
- Transformed features to:
  - Mean â‰ˆ 0
  - Standard deviation â‰ˆ 1
- Scaling ensures:
  - Faster convergence
  - Balanced feature contribution
  - Improved numerical stability

---

## ğŸ“Š Exploratory Data Analysis (EDA)

### Feature Distributions (Before Scaling)
- Histogram + KDE plots for:
  - `Data`
  - `Data_Change`
- Revealed scale imbalance between features

### Feature Distributions (After Scaling)
- Confirmed normalization
- Both features centered around zero
- Comparable spread across features

---

## ğŸ”€ Train-Test Split

- Data split into:
  - **80% Training**
  - **20% Testing**
- Used `random_state=42` for reproducibility
- Ensured fair evaluation on unseen data

---

## ğŸ¤– Machine Learning Models

### ğŸ”¹ Model 1: Linear Regression (Baseline)

- Simple and interpretable
- Assumes linear relationship between features and stock price
- Used as a benchmark model

#### Evaluation Metrics
- Mean Squared Error (MSE)
- R-squared (RÂ²)

---

### ğŸ”¹ Model 2: RandomForestRegressor (Advanced Model)

- Ensemble-based model using multiple decision trees
- Captures **non-linear relationships**
- More robust to volatility and noise

#### Why Random Forest?
- Financial data is often non-linear
- Handles interactions automatically
- Reduces overfitting via averaging

---

## ğŸ“Š Model Evaluation

### Metrics Used
- **Mean Squared Error (MSE)**
- **R-squared (RÂ²)**

### Results
- Linear Regression provided a strong baseline
- **Random Forest achieved lower MSE and higher RÂ²**
- Indicates superior predictive capability

---

## ğŸ“ˆ Visualization & Interpretation

### 1ï¸âƒ£ Time-Series Plots
- Actual vs Predicted prices for:
  - Linear Regression
  - Random Forest
- Used to observe trend-following behavior

### 2ï¸âƒ£ Scatter Plots
- Actual vs Predicted (with perfect prediction line)
- Used to:
  - Detect bias
  - Analyze error spread

### 3ï¸âƒ£ Combined Model Comparison Plot
- Actual prices vs:
  - Linear Regression predictions
  - Random Forest predictions
- Clearly shows Random Forest tracks actual prices more closely

---

## ğŸ”® Prediction & Deployment

### Prediction Functions Implemented

#### Linear Regression
```python
predict_stock_price(data, data_change)
